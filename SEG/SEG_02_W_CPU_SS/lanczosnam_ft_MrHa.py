import numpy as np
from sklearn.cluster import KMeans
from skimage import io, color
import time
import os
import pandas as pd
from datetime import datetime
import logging
from scipy.sparse import diags, csr_matrix
from joblib import Parallel, delayed
from numba import jit, prange

# HÃ m tÃ­nh ma tráº­n RBF song song vá»›i Ä‘áº§u ra lÃ  ma tráº­n thÆ°a
def compute_rbf_matrix_parallel(X, gamma, threshold=0.005, chunk_size=100):  # Giáº£m threshold
    """TÃ­nh ma tráº­n RBF Kernel song song vá»›i Ä‘áº§u ra lÃ  ma tráº­n thÆ°a."""
    n, d = X.shape
    W_data = []
    W_row = []
    W_col = []
    
    def compute_chunk(i_start, i_end):
        local_data = []
        local_row = []
        local_col = []
        for i in range(i_start, i_end):
            for j in range(n):
                dist = np.sum((X[i] - X[j]) ** 2)
                value = np.exp(-gamma * dist)
                if value > threshold:
                    local_data.append(value)
                    local_row.append(i)
                    local_col.append(j)
        return local_data, local_row, local_col
    
    chunks = [(i, min(i + chunk_size, n)) for i in range(0, n, chunk_size)]
    results = Parallel(n_jobs=-1)(delayed(compute_chunk)(i, j) for i, j in chunks)
    
    # GhÃ©p cÃ¡c káº¿t quáº£ tá»« tá»«ng pháº§n láº¡i
    for data, row, col in results:
        W_data.extend(data)
        W_row.extend(row)
        W_col.extend(col)
    
    W = csr_matrix((W_data, (W_row, W_col)), shape=(n, n))
    return W

# TÃ­nh ma tráº­n trá»ng sá»‘ song song vá»›i Ä‘áº§u ra lÃ  ma tráº­n thÆ°a
def compute_weight_matrix(image, sigma_i=0.3, sigma_x=20.0, chunk_size=100):  # Tinh chá»‰nh sigma
    """TÃ­nh ma tráº­n trá»ng sá»‘ song song vá»›i Ä‘áº§u ra lÃ  ma tráº­n thÆ°a."""
    h, w, c = image.shape
    coords = np.array(np.meshgrid(np.arange(h), np.arange(w))).reshape(2, -1).T
    features = image.reshape(-1, c)
    
    gamma_i = 1 / (2 * sigma_i**2)
    gamma_x = 1 / (2 * sigma_x**2)
    
    start_features = time.time()
    W_features = compute_rbf_matrix_parallel(features, gamma_i, threshold=0.005, chunk_size=chunk_size)
    end_features = time.time()
    W_features_time = end_features - start_features
    
    start_coords = time.time()
    W_coords = compute_rbf_matrix_parallel(coords, gamma_x, threshold=0.005, chunk_size=chunk_size)
    end_coords = time.time()
    W_coords_time = end_coords - start_coords
    
    # NhÃ¢n hai ma tráº­n thÆ°a
    W = W_features.multiply(W_coords)
    return W, W_features_time, W_coords_time

# TÃ­nh ma tráº­n Laplacian vá»›i ma tráº­n thÆ°a
def compute_laplacian(W):
    D_diag = W.sum(axis=1).A1
    D = diags(D_diag)
    L = D - W
    return L, D

# HÃ m tÃ­ch vÃ´ hÆ°á»›ng vá»›i Numba
@jit(nopython=True)
def handle_dot(a, b):
    result = 0.0
    for i in range(len(a)):
        result += a[i] * b[i]
    return result

# NhÃ¢n ma tráº­n-vector vá»›i Numba (song song hÃ³a cho ma tráº­n thÆ°a)
@jit(nopython=True, parallel=True)
def matrix_vector_product(A_data, A_indices, A_indptr, v, n, num_threads=os.cpu_count()):
    result = np.zeros(n)
    if n > 5000:  # NgÆ°á»¡ng kÃ­ch hoáº¡t song song hÃ³a
        # num_threads = n.mod(5000) > num_threads ? num_threads : n.mod(5000) 
        chunk_size = n // num_threads 
    for t in prange(num_threads):
        start = t * chunk_size
        end = (t + 1) * chunk_size if t < num_threads - 1 else n
        for i in range(start, end):
            for j in range(A_indptr[i], A_indptr[i + 1]):
                result[i] += A_data[j] * v[A_indices[j]]
    return result

# Thuáº­t toÃ¡n Lanczos cho ma tráº­n thÆ°a vá»›i song song hÃ³a cáº£i tiáº¿n
@jit(nopython=True, parallel=True)
def lanczos_sparse(A_data, A_indices, A_indptr, v, m, n, num_threads=os.cpu_count()):
    V = np.zeros((m, n))
    T = np.zeros((m, m))
    V[0, :] = v / np.linalg.norm(v)
    
    w = matrix_vector_product(A_data, A_indices, A_indptr, V[0, :], n)
    alpha = handle_dot(w, V[0, :])
    w = w - alpha * V[0, :]
    T[0, 0] = alpha
    
    # chunk_size = m // num_threads
    zero_vector = np.zeros(n, dtype=np.float64)  # ThÃªm zero vector cho nhÃ¡nh else
    for j in prange(1, m):  # Song song hÃ³a vÃ²ng láº·p j -- á»Ÿ Ä‘Ã¢y thÃ¬ nÃ³ sáº½ khÃ´ng song song Ä‘Æ°á»£c tá»‘i Æ°u vÃ¬ cÃ³ break á»Ÿ trong (https://x.com/i/grok?conversation=1900765140427141218)
        beta = np.linalg.norm(w)
        if beta < 1e-10:
            break
        V[j, :] = w / beta
        # Trá»±c giao hÃ³a (Gram-Schmidt) cháº·t cháº½
        for i in range(j):
            proj = handle_dot(V[j, :], V[i, :])
            V[j, :] -= proj * V[i, :]
        norm_vj = np.linalg.norm(V[j, :])
        if norm_vj < 1e-10:
            break
        V[j, :] /= norm_vj
        
        w = matrix_vector_product(A_data, A_indices, A_indptr, V[j, :], n)
        alpha = handle_dot(w, V[j, :])
        w = w - alpha * V[j, :] - (beta * V[j-1, :] if j > 0 else zero_vector)  # Sá»­ dá»¥ng zero_vector
    
        T[j, j] = alpha
        if j > 0:
            T[j-1, j] = beta
            T[j, j-1] = beta
    
    # Äáº£m báº£o T Ä‘á»‘i xá»©ng
    T = (T + T.T) / 2
    return T, V

# TÃ­nh trá»‹ riÃªng vÃ  vector riÃªng
def compute_eigen(L, D, k=2):
    D_diag = D.diagonal().copy()
    D_diag[D_diag < 1e-10] = 1e-10
    D_inv_sqrt = diags(1.0 / np.sqrt(D_diag))
    L_normalized = D_inv_sqrt @ L @ D_inv_sqrt
    
    v0 = np.random.rand(L.shape[0])
    v0 /= np.linalg.norm(v0)
    
    n = L.shape[0]
    L_csr = L_normalized.tocsr()
    start_lanczos = time.time()
    T, V = lanczos_sparse(L_csr.data, L_csr.indices, L_csr.indptr, v0, m=k + 50, n=n)
    end_lanczos = time.time()
    
    lanczos_time = end_lanczos - start_lanczos
    logging.info(f"Thá»i gian Lanczos: {lanczos_time:.6f} giÃ¢y, n={n}")
    
    # Láº¥y kÃ­ch thÆ°á»›c thá»±c táº¿ cá»§a T
    j = T.shape[0] - 1  # Sá»‘ láº§n láº·p thá»±c táº¿
    if j < k:
        raise ValueError(f"Sá»‘ láº§n láº·p thá»±c táº¿ ({j}) nhá» hÆ¡n k ({k})")
    
    # TÃ­nh trá»‹ riÃªng vÃ  vector riÃªng cá»§a ma tráº­n T
    eigvals, eigvecs_T = np.linalg.eig(T)
    idx = np.argsort(eigvals)
    eigvals = eigvals[idx]
    eigvecs_T = eigvecs_T[:, idx]
    
    # Bá» vector riÃªng nhá» nháº¥t (trá»‹ riÃªng gáº§n 0) vÃ  láº¥y k vector
    eigvecs_T = eigvecs_T[:, 1:k+1]
    eigvecs_original = D_inv_sqrt @ (V[:j+1, :].T @ eigvecs_T)
    
    # Chuáº©n hÃ³a vector riÃªng ká»¹ hÆ¡n
    for i in range(eigvecs_original.shape[1]):
        norm = np.linalg.norm(eigvecs_original[:, i])
        if norm > 1e-10:
            eigvecs_original[:, i] /= norm
        else:
            eigvecs_original[:, i] = np.zeros_like(eigvecs_original[:, i])
    
    logging.info(f"Trá»‹ riÃªng: {eigvals[:k+1]}")
    logging.info(f"Vector riÃªng (máº«u): {eigvecs_original[:5, :]}")
    return eigvecs_original, lanczos_time

# GÃ¡n nhÃ£n
def assign_labels(eigen_vectors, k):
    return KMeans(n_clusters=k, random_state=42, n_init=50).fit(eigen_vectors).labels_  # TÄƒng n_init

# LÆ°u file .seg
def save_seg_file(labels, image_shape, output_path, image_name="image"):
    h, w = image_shape[:2]
    labels_2d = labels.reshape(h, w)
    unique_labels = np.unique(labels)
    segments = len(unique_labels)

    header = [
        "format ascii cr",
        f"date {datetime.now().strftime('%a %b %d %H:%M:%S %Y')}",
        f"image {image_name}",
        "user 1102",
        f"width {w}",
        f"height {h}",
        f"segments {segments}",
        "gray 0",
        "invert 0",
        "flipflop 0",
        "data"
    ]

    data_lines = []
    for row in range(h):
        row_labels = labels_2d[row, :]
        start_col = 0
        current_label = row_labels[0]

        for col in range(1, w):
            if row_labels[col] != current_label:
                data_lines.append(f"{int(current_label)} {row} {start_col} {col - 1}")
                start_col = col
                current_label = row_labels[col]
        data_lines.append(f"{int(current_label)} {row} {start_col} {w - 1}")

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("\n".join(header) + "\n")
        f.write("\n".join(data_lines) + "\n")
    print(f"âœ… File SEG Ä‘Ã£ lÆ°u: {output_path}")

# HÃ m chÃ­nh xá»­ lÃ½ áº£nh
def normalized_cuts(lan, imagename, image_path, output_path):
    start_cpu = time.time()
    image = io.imread(image_path)
    image = color.gray2rgb(image) if image.ndim == 2 else image[:, :, :3] if image.shape[2] == 4 else image
    image = image / 255.0
    k = 2

    W, W_f, W_c = compute_weight_matrix(image, sigma_i=0.3, sigma_x=20.0)
    W_all = W_f + W_c
    L, D = compute_laplacian(W)
    vecs, lanczos_time = compute_eigen(L, D, k)  # Láº¥y thÃªm lanczos_time
    labels = assign_labels(vecs, k)

    seg_output_path = f"{imagename}_segmentation_{lan}.seg"
    save_seg_file(labels, image.shape, seg_output_path, imagename)

    end_cpu = time.time()
    total_cpu_time = end_cpu - start_cpu
    return total_cpu_time, W_f, W_c, W_all, lanczos_time  # ThÃªm lanczos_time vÃ o káº¿t quáº£ tráº£ vá»

# HÃ m cháº¡y nhiá»u áº£nh vÃ  lÆ°u káº¿t quáº£ - cáº­p nháº­t Ä‘á»ƒ thÃªm cá»™t thá»i gian Lanczos
def kiemThuChayNhieuLan(i, name, folder_path, output_excel_base="results"):
    if not os.path.isdir(folder_path):
        print(f"âŒ ThÆ° má»¥c {folder_path} khÃ´ng tá»“n táº¡i!")
        return

    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
    if not image_files:
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file áº£nh nÃ o trong {folder_path}!")
        return

    results = []
    for idx, file_name in enumerate(image_files, start=1):
        image_path = os.path.join(folder_path, file_name)
        print(f"ğŸ“· Äang xá»­ lÃ½ áº£nh {idx}: {image_path}")

        imagename = os.path.splitext(file_name)[0]
        total_time, wf_time, wc_time, W_all, lanczos_time = normalized_cuts(i, imagename, image_path, output_excel_base)
        results.append([i, idx, file_name, wf_time, wc_time, W_all, lanczos_time])

    df = pd.DataFrame(results, columns=[
        "Láº§n cháº¡y", 
        "áº¢nh sá»‘", 
        "TÃªn áº£nh", 
        "Thá»i gian W Ä‘áº·c trÆ°ng (s)", 
        "Thá»i gian W tá»a Ä‘á»™ (s)", 
        "Thá»i gian W All", 
        "Thá»i gian Lanczos (s)"  # ThÃªm cá»™t má»›i
    ])
    output_excel = f"{output_excel_base}_{name}_{i}.xlsx"
    df.to_excel(output_excel, index=False, engine='openpyxl')
    print(f"âœ… Káº¿t quáº£ Excel Ä‘Ã£ lÆ°u vÃ o {output_excel}")