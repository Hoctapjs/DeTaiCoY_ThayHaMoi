import cupy as cp  # Thay th·∫ø NumPy b·∫±ng CuPy
import matplotlib.pyplot as plt
from sklearn.metrics.pairwise import rbf_kernel
# from scipy.sparse.linalg import eigsh
from sklearn.cluster import KMeans
from skimage import io, color
import cupyx.scipy.sparse as sp
from cupyx.scipy.sparse.linalg import eigsh
import time
from tkinter import Tk
from tkinter.filedialog import askopenfilename
import logging
import os
import re
from  cupyx.scipy.sparse import diags
import pandas as pd

def kiemThuChayNhieuLan(i, name, folder_path, output_excel="results.xlsx"):
    # Ki·ªÉm tra th∆∞ m·ª•c
    if not os.path.isdir(folder_path):
        print(f"‚ùå Th∆∞ m·ª•c {folder_path} kh√¥ng t·ªìn t·∫°i!")
        return
    
    # L·∫•y danh s√°ch file ·∫£nh
    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif'))]
    
    if not image_files:
        print(f"‚ùå Kh√¥ng t√¨m th·∫•y file ·∫£nh n√†o trong {folder_path}!")
        return

    results = []  # Danh s√°ch l∆∞u k·∫øt qu·∫£

    for idx, file_name in enumerate(image_files, start=1):
        image_path = os.path.join(folder_path, file_name)
        print(f"üì∑ ƒêang x·ª≠ l√Ω ·∫£nh {idx}: {image_path}")
        
        # X·ª≠ l√Ω ·∫£nh
        _, wf_time, wc_time   = normalized_cuts(i, file_name, image_path, output_excel)  # B·ªè time_w v√¨ kh√¥ng c·∫ßn
        
        # L∆∞u k·∫øt qu·∫£ v√†o danh s√°ch
        results.append([i, idx, file_name, wf_time, wc_time])

    # Ghi k·∫øt qu·∫£ v√†o file Excel
    df = pd.DataFrame(results, columns=["L·∫ßn ch·∫°y", "·∫¢nh s·ªë", "T√™n ·∫£nh", "Th·ªùi gian W ƒë·∫∑c tr∆∞ng (s)", "Th·ªùi gian W t·ªça ƒë·ªô (s)"])


    # T·∫°o t√™n file k·∫øt qu·∫£ theo format chu·∫©n
    output_excel = f"result_{name}_{i}.xlsx"
    
    df.to_excel(output_excel, index=False, engine='openpyxl')
    print(f"‚úÖ K·∫øt qu·∫£ ƒë√£ l∆∞u v√†o {output_excel}")





# CUDA Kernel ƒë·ªÉ t√≠nh RBF Kernel song song
rbf_kernel_cuda = cp.RawKernel(r'''
extern "C" __global__
void rbf_kernel(const double* X, double* W, int n, int d, double gamma) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i >= n) return;
    
    for (int j = 0; j < n; j++) {
        double dist = 0.0;
        for (int k = 0; k < d; k++) {
            double diff = X[i * d + k] - X[j * d + k];
            dist += diff * diff;
        }
        W[i * n + j] = exp(-gamma * dist);
    }
}
''', 'rbf_kernel')

def compute_rbf_matrix(X, gamma, threads_per_block=1024):
    n, d = X.shape
    X_gpu = cp.asarray(X, dtype=cp.float64)
    W_gpu = cp.zeros((n, n), dtype=cp.float64)

    # T√≠nh s·ªë block c·∫ßn thi·∫øt
    num_blocks = (n + threads_per_block - 1) // threads_per_block

    # G·ªçi CUDA Kernel
    rbf_kernel_cuda((num_blocks,), (threads_per_block,), (X_gpu, W_gpu, n, d, gamma))

    return W_gpu


# 1. Tinh ma tran trong so
def compute_weight_matrix(image, sigma_i=0.1, sigma_x=10, threads_per_block=300):
    h, w, c = image.shape
    coords = cp.array(cp.meshgrid(cp.arange(h), cp.arange(w))).reshape(2, -1).T  # T·ªça ƒë·ªô (x, y)
    features = cp.array(image.reshape(-1, c))  # Chuy·ªÉn to√†n b·ªô ƒë·∫∑c tr∆∞ng l√™n GPU

    # logging.info(f"K√≠ch th∆∞·ªõc ·∫£nh: {h}x{w}x{c}")
    # logging.info(f"K√≠ch th∆∞·ªõc ƒë·∫∑c tr∆∞ng m√†u: {features.shape}, K√≠ch th∆∞·ªõc t·ªça ƒë·ªô: {coords.shape}")

    gamma_i = 1 / (2 * sigma_i**2)
    gamma_x = 1 / (2 * sigma_x**2)

    
    

    start_features = time.time()
    W_features = compute_rbf_matrix(features, gamma_i, threads_per_block)
    cp.cuda.Stream.null.synchronize()
    end_features = time.time()

    W_features_time =  end_features - start_features

    # t√≠nh th·ªùi gian w t·ªça ƒë·ªô
    start_coords = time.time()
    W_coords = compute_rbf_matrix(coords, gamma_x, threads_per_block)
    cp.cuda.Stream.null.synchronize()
    end_coords = time.time()

    W_coords_time =  end_coords - start_coords

    W = cp.multiply(W_features, W_coords)
    return W, W_features_time, W_coords_time



# 2. Tinh ma tran Laplace
def compute_laplacian(W_sparse):
    # T·ªïng c·ªßa c√°c h√†ng trong ma tr·∫≠n W
    D_diag = W_sparse.sum(axis=1).get().flatten()  # T√≠nh t·ªïng c√°c h√†ng
    D = cp.diag(D_diag)  # T·∫°o ma tr·∫≠n ƒë∆∞·ªùng ch√©o t·ª´ t·ªïng h√†ng
    L = D - W_sparse  # L = D - W
    # logging.info("Kich thuoc ma tran duong cheo (D): %s", D.shape)
    # logging.info("Mau cua D (9 phan tu dau):\n%s", D_diag[:9])  # In ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o
    # logging.info("Kich thuoc ma tran Laplace (L): %s", L.shape)
    # logging.info("Mau cua L (9x9 phan tu dau):\n%s", L[:9, :9])
    return L, D

def Lanczos(A, v, m):
    """
    Thu·∫≠t to√°n Lanczos ƒë·ªÉ x·∫•p x·ªâ tr·ªã ri√™ng v√† vector ri√™ng.
    : A: Ma tr·∫≠n c·∫ßn t√≠nh (numpy 2D array).
    : v: Vector kh·ªüi t·∫°o.
    : m: S·ªë b∆∞·ªõc l·∫∑p Lanczos.
    :return: Ma tr·∫≠n tam gi√°c T v√† ma tr·∫≠n tr·ª±c giao V.
    """
    n = len(v) # ƒê√¢y l√† s·ªë ph·∫ßn t·ª≠ trong vector v (s·ªë chi·ªÅu c·ªßa ma tr·∫≠n A)
    V = cp.zeros((m, n)) # ƒë√¢y l√† m·ªôt ma tr·∫≠n mxn l∆∞u tr·ªØ c√°c vector tr·ª±c giao (l√† 2 vector c√≥ t√≠ch v√¥ h∆∞·ªõng = 0), m·ªói h√†ng l√† m·ªôt b∆∞·ªõc ƒë√£ ƒëi qua, np.zeros nghƒ©a l√† ban ƒë·∫ßu t·∫•t c·∫£ c√°c b∆∞·ªõc ƒëi (hay c√°c ph·∫ßn t·ª≠ c·ªßa ma tr·∫≠n) ƒë·ªÅu l√† 0, ch∆∞a ƒëi b∆∞·ªõc n√†o
    T = cp.zeros((m, m)) # ƒë√¢y l√† ma tr·∫≠n tam gi√°c T
    V[0, :] = v / cp.linalg.norm(v) # np.linalg.norm(v) l√† ƒë·ªÉ t√≠nh chu·∫©n (ƒë·ªô d√†i) c·ªßa vector = cƒÉn(v1^2 + v2^2 + ...)
    # => V[0, :] = v / np.linalg.norm(v) l√† ƒë·ªÉ chu·∫©n h√≥a vector v ƒë·∫ßu v√†o th√†nh vector ƒë∆°n v·ªã 
    
    # ƒêo·∫°n n√†y l√† ƒë·ªÉ l√†m cho w tr·ª±c giao v·ªõi V0 th√¥i
    # vd: ƒë·ªÉ l√†m cho 2 vector a v√† b tr·ª±c giao v·ªõi nhau
    # 1. t√≠nh t√≠ch v√¥ h∆∞·ªõng c·ªßa a v√† b (alpha)
    # 2. c·∫≠p nh·∫≠t vector a l·∫°i 
    #   a = a - alpha * b (b ·ªü ƒë√¢y l√† V[0, :] = v / cƒÉn(v) )


    w = A @ V[0, :] # t√≠nh vector w b·∫±ng c√°ch nh√¢n A v·ªõi vector ƒë·∫ßu ti√™n c·ªßa V - hi·ªÉu n√¥m na l√† w s·∫Ω cho ta bi·∫øt c√°c m√† ma tr·∫≠n A t∆∞∆°ng t√°c v·ªõi vector kh·ªüi t·∫°o v
    alpha = cp.dot(w, V[0, :]) # .dot l√† t√≠nh t√≠ch v√¥ h∆∞·ªõng c·ªßa 2 vector a v√† b (trong case n√†y l√† w v√† vector ƒë·∫ßu ti√™n c·ªßa V), h·ªá s·ªë alpha l√† ƒë·ªÉ ƒëo m·ª©c ƒë·ªô song song gi·ªØa w v√† V0
    w = w - alpha * V[0, :]
    # alpha * V[0, :] t·∫°o ra m·ªôt vector c√≥ h∆∞·ªõng song song v·ªõi 
    # V[0,:] m√† c√≥ ƒë·ªô d√†i t∆∞∆°ng ·ª©ng.
    # sau khi tr·ª´ xong th√¨ n√≤ s·∫Ω lo·∫°i b·ªè ph·∫ßn song song ra kh·ªèi w

    
    T[0, 0] = alpha # G√°n gi√° tr·ªã alpha v√†o ph·∫ßn t·ª≠ ƒë·∫ßu ti√™n c·ªßa T
    
    for j in range(1, m):
        beta = cp.linalg.norm(w)
        if beta < 1e-10:
            break
        V[j, :] = w / beta
        w = A @ V[j, :]
        alpha = cp.dot(w, V[j, :])
        w = w - alpha * V[j, :] - beta * V[j-1, :]
        
        T[j, j] = alpha
        T[j-1, j] = beta
        T[j, j-1] = beta
    
    return T, V

def compute_eigen(L, D, k=2):
    """
    Gi·∫£i b√†i to√°n tr·ªã ri√™ng b·∫±ng thu·∫≠t to√°n Lanczos kh√¥ng d√πng eigsh.
    :param L: Ma tr·∫≠n Laplace th∆∞a (Scipy sparse matrix).
    :param D: Ma tr·∫≠n ƒë∆∞·ªùng ch√©o (Scipy sparse matrix).
    :param k: S·ªë tr·ªã ri√™ng nh·ªè nh·∫•t c·∫ßn t√≠nh.
    :return: C√°c vector ri√™ng t∆∞∆°ng ·ª©ng (k vector).
    """
    # Chuan hoa ma tran Laplace: D^-1/2 * L * D^-1/2
    D_diag = D.diagonal().copy()  # Lay duong cheo cua D
    D_diag[D_diag < 1e-10] = 1e-10  # Tranh chia cho 0 hoac gan 0
    D_inv_sqrt = diags(1.0 / cp.sqrt(D_diag))  # Tinh D^-1/2
    L_normalized = D_inv_sqrt @ L @ D_inv_sqrt  # Chuan hoa ma tran Laplace
    
    # Kh·ªüi t·∫°o vector ng·∫´u nhi√™n
    v0 = cp.random.rand(L.shape[0])
    v0 /= cp.linalg.norm(v0)
    
    # √Åp d·ª•ng thu·∫≠t to√°n Lanczos
    T, V = Lanczos(L_normalized, v0, m=k+5)  # S·ª≠ d·ª•ng m > k ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c
    
    # T√≠nh tr·ªã ri√™ng v√† vector ri√™ng c·ªßa ma tr·∫≠n tam gi√°c T
    eigvals, eigvecs_T = cp.linalg.eigh(T[:k, :k])
    
    # Chuy·ªÉn ƒë·ªïi vector ri√™ng v·ªÅ kh√¥ng gian g·ªëc
    eigvecs_original = D_inv_sqrt @ (V[:k, :].T @ eigvecs_T)
    
    return eigvecs_original

# 4. Gan nhan cho tung diem anh duoc dua tren vector rieng
def assign_labels(eigen_vectors, k):
    # Chuyen du lieu ve CPU de dung K-Means
    eigen_vectors_cpu = eigen_vectors.get()
    # logging.info(f"Manh cua vector rieng (9 hang dau):\n{eigen_vectors_cpu[:9, :]}")

    kmeans = KMeans(n_clusters=k, random_state=0).fit(eigen_vectors_cpu)
    labels = kmeans.labels_
    # logging.info(f"Nhan gan cho 27 pixel dau tien: {labels[:27]}")
    return cp.array(labels)  # Chuyen lai ve GPU

def save_segmentation(image, labels, k, output_path):
    h, w, c = image.shape
    segmented_image = cp.zeros_like(image, dtype=cp.uint8)
    for i in range(k):
        mask = labels.reshape(h, w) == i
        cluster_pixels = image.get()[mask]
        mean_color = (cluster_pixels.mean(axis=0) * 255).astype(cp.uint8) if len(cluster_pixels) > 0 else cp.array([0, 0, 0], dtype=cp.uint8)
        segmented_image[mask] = mean_color
    io.imsave(output_path, segmented_image)

# 6. Ket hop toan bo
def normalized_cuts(lan, imagename, image_path, output_path):
    
    # Tinh toan tren GPU
    start_gpu = time.time()
    logging.info(f"file name: {imagename}")
    logging.info(f"Lan thu: {lan}")
    # Doc anh va chuan hoa
    image = io.imread(image_path)
    if image.ndim == 2:  # Neu la anh xam, chuyen thanh RGB
        image = color.gray2rgb(image)
    elif image.shape[2] == 4:  # Neu la anh RGBA, loai bo kenh alpha
        image = image[:, :, :3]
    image = image / 255.0  # Chuan hoa ve [0, 1]
    
    k=3

    # Tinh toan Ncuts
    start_cpu_coo = time.time()
    W, W_f, W_c = compute_weight_matrix(image)
    end_cpu_coo = time.time()

    L, D = compute_laplacian(W)
    
    eigen_vectors = compute_eigen(L,D, k=k)  # Tinh k vector rieng
    
    labels = assign_labels(eigen_vectors, k)  # Gan nhan cho moi diem anh
    # save_segmentation(image, labels, k, output_path)

    cp.cuda.Stream.null.synchronize()  # Dong bo hoa de dam bao GPU hoan thanh tinh toan
    end_gpu = time.time()
    logging.info(f"Thoi gian: {end_gpu - start_gpu} giay")
    logging.info(f"Thoi gian W: {end_cpu_coo - start_cpu_coo} giay")
    
    # # ‚úÖ Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU sau khi s·ª≠ d·ª•ng
    # del W, L, D, eigen_vectors
    # cp.get_default_memory_pool().free_all_blocks()
    # cp.get_default_pinned_memory_pool().free_all_blocks()
    # cp.cuda.Device(0).synchronize()  # ƒê·∫£m b·∫£o gi·∫£i ph√≥ng ho√†n to√†n
    
    return (end_cpu_coo - start_cpu_coo), W_f, W_c
    # display_segmentation(image, labels, k)


# # 8. Chay thu nghiem
# if __name__ == "__main__":
